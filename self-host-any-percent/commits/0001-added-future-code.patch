From 8c72f0b290004fcee9f0faf54205cb7046376ad5 Mon Sep 17 00:00:00 2001
From: SimonFJ20 <simonfromjakobsen@gmail.com>
Date: Sat, 30 Jul 2022 04:53:24 +0200
Subject: [PATCH] added future code

---
 src/checker.rs |  29 ++++++
 src/codegen.rs |   1 +
 src/common.rs  |  42 ++++++++
 src/lexer.rs   |  95 +++++++++++++++++++
 src/main.rs    | 253 ++++---------------------------------------------
 src/parser.rs  |  91 ++++++++++++++++++
 6 files changed, 275 insertions(+), 236 deletions(-)
 create mode 100644 src/checker.rs
 create mode 100644 src/codegen.rs
 create mode 100644 src/common.rs
 create mode 100644 src/lexer.rs
 create mode 100644 src/parser.rs

diff --git a/src/checker.rs b/src/checker.rs
new file mode 100644
index 0000000..8388031
--- /dev/null
+++ b/src/checker.rs
@@ -0,0 +1,29 @@
+use crate::{common::*, parser::*};
+
+pub enum Type {
+    I32,
+}
+
+pub enum CheckedExpression {
+    Expression(Box<CheckedExpression>, Type, Span),
+    Add(Box<CheckedExpression>, Box<CheckedExpression>, Type, Span),
+    Int(String, Type, Span),
+}
+
+pub struct Checker {
+    errors: Vec<Error>,
+}
+
+impl Checker {
+    pub fn new() -> Self {
+        Self { errors: Vec::new() }
+    }
+
+    pub fn errors(&self) -> Vec<Error> {
+        self.errors.clone()
+    }
+
+    pub fn check(ast: ParsedExpression) -> Result<CheckedExpression, Vec<Error>> {
+        todo!()
+    }
+}
diff --git a/src/codegen.rs b/src/codegen.rs
new file mode 100644
index 0000000..8b13789
--- /dev/null
+++ b/src/codegen.rs
@@ -0,0 +1 @@
+
diff --git a/src/common.rs b/src/common.rs
new file mode 100644
index 0000000..66dae2b
--- /dev/null
+++ b/src/common.rs
@@ -0,0 +1,42 @@
+#[derive(Debug, Clone)]
+pub enum Error {
+    LexerError(String),
+    ParserError(String),
+}
+
+pub type FileId = usize;
+
+#[derive(Debug, Clone)]
+pub struct Span {
+    pub file_id: FileId,
+    pub start: usize,
+    pub end: usize,
+}
+
+impl Span {
+    pub fn new(file_id: FileId, start: usize, end: usize) -> Self {
+        Self {
+            file_id,
+            start,
+            end,
+        }
+    }
+
+    pub fn contains(self, span: Span) -> bool {
+        self.file_id == span.file_id && span.start >= self.start && span.end >= self.end
+    }
+
+    pub fn merge(a: &Span, b: &Span) -> Self {
+        if a.file_id != b.file_id {
+            panic!("file_id must match")
+        }
+        if a.start >= b.end {
+            panic!("a must start before b ends")
+        }
+        Self {
+            file_id: a.file_id,
+            start: a.start,
+            end: b.end,
+        }
+    }
+}
diff --git a/src/lexer.rs b/src/lexer.rs
new file mode 100644
index 0000000..620e018
--- /dev/null
+++ b/src/lexer.rs
@@ -0,0 +1,95 @@
+use crate::common::*;
+
+#[derive(Debug, Clone)]
+pub enum TokenContents {
+    Int(String),
+    Plus,
+    LParen,
+    RParen,
+    EOF,
+    Invalid,
+}
+
+#[derive(Debug, Clone)]
+pub struct Token {
+    pub contents: TokenContents,
+    pub span: Span,
+}
+
+impl Token {
+    pub fn new(contents: TokenContents, span: Span) -> Self {
+        Self { contents, span }
+    }
+}
+
+pub fn tokenize(file_id: FileId, text: &[u8]) -> (Vec<Token>, Vec<Error>) {
+    use TokenContents::*;
+    let index = &mut 0;
+    let mut tokens: Vec<Token> = Vec::new();
+    let mut errors: Vec<Error> = Vec::new();
+    while *index < text.len() {
+        match text[*index] {
+            b'+' => tokens.push(single_char_tok(file_id, index, Plus)),
+            b'(' => tokens.push(single_char_tok(file_id, index, LParen)),
+            b')' => tokens.push(single_char_tok(file_id, index, RParen)),
+            _ => match make_token(file_id, text, index) {
+                Ok(token) => tokens.push(token),
+                Err(error) => errors.push(error),
+            },
+        }
+    }
+    (tokens, errors)
+}
+
+fn single_char_tok(file_id: FileId, index: &mut usize, contents: TokenContents) -> Token {
+    let start = *index;
+    *index += 1;
+    Token::new(contents, Span::new(file_id, start, *index))
+}
+
+fn make_token(file_id: FileId, text: &[u8], index: &mut usize) -> Result<Token, Error> {
+    while text[*index].is_ascii_whitespace() {
+        *index += 1;
+    }
+    if text[*index] == b'0' {
+        let start = *index;
+        *index += 1;
+        if *index >= text.len() {
+            *index += 1;
+            Ok(Token::new(
+                TokenContents::Int(String::from_utf8_lossy(&text[start..*index]).to_string()),
+                Span::new(file_id, start, *index),
+            ))
+        } else {
+            match text[*index] {
+                b'x' => todo!(),
+                b'o' => todo!(),
+                b'b' => todo!(),
+                _ => Err(Error::LexerError("cannot start literal with 0".into())),
+            }
+        }
+    } else if text[*index].is_ascii_digit() {
+        let start = *index;
+        while *index < text.len() && text[*index].is_ascii_digit() {
+            *index += 1;
+        }
+        Ok(Token::new(
+            TokenContents::Int(String::from_utf8_lossy(&text[start..*index]).to_string()),
+            Span::new(file_id, start, *index),
+        ))
+    } else {
+        let start = *index;
+        *index += 1;
+        match text[start] {
+            b'+' => Ok(Token::new(
+                TokenContents::Plus,
+                Span::new(file_id, start, *index),
+            )),
+            _ => Err(Error::LexerError(format!(
+                "unexpected char '{}' == {}",
+                char::from(text[*index]),
+                text[*index],
+            ))),
+        }
+    }
+}
diff --git a/src/main.rs b/src/main.rs
index 0320fd1..7a6deaa 100644
--- a/src/main.rs
+++ b/src/main.rs
@@ -1,247 +1,28 @@
-use core::panic;
+use lexer::*;
+use parser::*;
 
-#[derive(Debug)]
-pub enum Error {
-    LexerError(String),
-    ParserError(String),
-}
-
-#[derive(Debug)]
-pub enum ParsedExpression {
-    Expression(Box<ParsedExpression>, Span),
-    Add(Box<ParsedExpression>, Box<ParsedExpression>, Span),
-    Int(String, Span),
-    Invalid(Error, Span),
-}
-
-impl ParsedExpression {
-    pub fn span(&self) -> &Span {
-        match self {
-            ParsedExpression::Expression(_, span) => span,
-            ParsedExpression::Add(_, _, span) => span,
-            ParsedExpression::Int(_, span) => span,
-            ParsedExpression::Invalid(_, span) => span,
-        }
-    }
-}
-
-pub fn parse(file_id: FileId, text: &[u8]) -> (ParsedExpression, Vec<Error>) {
-    let (tokens, errors) = tokenize(file_id, text);
-    let mut parser = Parser::new(file_id, tokens, errors);
-    let expression = parser.parse_expression();
-    (expression, parser.errors)
-}
-
-pub struct Parser {
-    file_id: FileId,
-    tokens: Vec<Token>,
-    errors: Vec<Error>,
-    index: usize,
-}
-
-impl Parser {
-    pub fn new(file_id: FileId, tokens: Vec<Token>, errors: Vec<Error>) -> Self {
-        Self {
-            file_id,
-            tokens,
-            errors,
-            index: 0,
-        }
-    }
-
-    pub fn parse_expression(&mut self) -> ParsedExpression {
-        self.parse_prec_11()
-    }
-
-    pub fn parse_prec_11(&mut self) -> ParsedExpression {
-        let left = self.parse_value();
-        if self.index >= self.tokens.len() {
-            return left;
-        }
-        let operator = self.tokens[self.index].clone();
-        match operator.contents {
-            TokenContents::Plus => {
-                self.index += 1;
-                let right = self.parse_prec_11();
-                let span = Span::merge(left.span(), right.span());
-                ParsedExpression::Add(Box::new(left), Box::new(right), span)
-            }
-            _ => left,
-        }
-    }
-
-    pub fn parse_value(&mut self) -> ParsedExpression {
-        let token = self.tokens[self.index].clone();
-        self.index += 1;
-        match token.contents {
-            TokenContents::Int(value) => ParsedExpression::Int(value, token.span),
-            TokenContents::LParen => {
-                let expr = self.parse_expression();
-                match self.tokens[self.index].contents {
-                    TokenContents::RParen => {
-                        let rparen = self.tokens[self.index].clone();
-                        self.index += 1;
-                        ParsedExpression::Expression(
-                            Box::new(expr),
-                            Span::merge(&token.span, &rparen.span),
-                        )
-                    }
-                    _ => ParsedExpression::Invalid(
-                        Error::ParserError("unexpected token".into()),
-                        Span::merge(&token.span, &self.tokens[self.index].span),
-                    ),
-                }
-            }
-            _ => {
-                ParsedExpression::Invalid(Error::ParserError("unexpected token".into()), token.span)
-            }
-        }
-    }
-}
-
-#[derive(Debug, Clone)]
-pub enum TokenContents {
-    Int(String),
-    Plus,
-    LParen,
-    RParen,
-    EOF,
-    Invalid,
-}
-
-pub type FileId = usize;
-
-#[derive(Debug, Clone, Copy)]
-pub struct Span {
-    pub file_id: FileId,
-    pub start: usize,
-    pub end: usize,
-}
-
-impl Span {
-    pub fn new(file_id: FileId, start: usize, end: usize) -> Self {
-        Self {
-            file_id,
-            start,
-            end,
-        }
-    }
-
-    pub fn contains(self, span: Span) -> bool {
-        self.file_id == span.file_id && span.start >= self.start && span.end >= self.end
-    }
-
-    pub fn merge(a: &Span, b: &Span) -> Self {
-        if a.file_id != b.file_id {
-            panic!("file_id must match")
-        }
-        if a.start >= b.end {
-            panic!("a must start before b ends")
-        }
-        Self {
-            file_id: a.file_id,
-            start: a.start,
-            end: b.end,
-        }
-    }
-}
-
-#[derive(Debug, Clone)]
-pub struct Token {
-    pub contents: TokenContents,
-    pub span: Span,
-}
-
-impl Token {
-    pub fn new(contents: TokenContents, span: Span) -> Self {
-        Self { contents, span }
-    }
-}
-
-pub fn tokenize(file_id: FileId, text: &[u8]) -> (Vec<Token>, Vec<Error>) {
-    use TokenContents::*;
-    let index = &mut 0;
-    let mut tokens: Vec<Token> = Vec::new();
-    let mut errors: Vec<Error> = Vec::new();
-    while *index < text.len() {
-        match text[*index] {
-            b'+' => tokens.push(single_char_tok(file_id, index, Plus)),
-            b'(' => tokens.push(single_char_tok(file_id, index, LParen)),
-            b')' => tokens.push(single_char_tok(file_id, index, RParen)),
-            _ => match make_token(file_id, text, index) {
-                Ok(token) => tokens.push(token),
-                Err(error) => errors.push(error),
-            },
-        }
-    }
-    (tokens, errors)
-}
-
-fn single_char_tok(file_id: FileId, index: &mut usize, contents: TokenContents) -> Token {
-    let start = *index;
-    *index += 1;
-    Token::new(contents, Span::new(file_id, start, *index))
-}
-
-fn make_token(file_id: FileId, text: &[u8], index: &mut usize) -> Result<Token, Error> {
-    while text[*index].is_ascii_whitespace() {
-        *index += 1;
-    }
-    if text[*index] == b'0' {
-        let start = *index;
-        *index += 1;
-        if *index >= text.len() {
-            *index += 1;
-            Ok(Token::new(
-                TokenContents::Int(String::from_utf8_lossy(&text[start..*index]).to_string()),
-                Span::new(file_id, start, *index),
-            ))
-        } else {
-            match text[*index] {
-                b'x' => todo!(),
-                b'o' => todo!(),
-                b'b' => todo!(),
-                _ => Err(Error::LexerError("cannot start literal with 0".into())),
-            }
-        }
-    } else if text[*index].is_ascii_digit() {
-        let start = *index;
-        while *index < text.len() && text[*index].is_ascii_digit() {
-            *index += 1;
-        }
-        Ok(Token::new(
-            TokenContents::Int(String::from_utf8_lossy(&text[start..*index]).to_string()),
-            Span::new(file_id, start, *index),
-        ))
-    } else {
-        let start = *index;
-        *index += 1;
-        match text[start] {
-            b'+' => Ok(Token::new(
-                TokenContents::Plus,
-                Span::new(file_id, start, *index),
-            )),
-            _ => Err(Error::LexerError(format!(
-                "unexpected char '{}' == {}",
-                char::from(text[*index]),
-                text[*index],
-            ))),
-        }
-    }
-}
+mod checker;
+mod codegen;
+mod common;
+mod lexer;
+mod parser;
 
 fn main() {
-    let text = "2 +3";
+    let text = "2 + 3 + 4";
     let (tokens, token_errors) = tokenize(0, text.as_bytes());
     if token_errors.is_empty() {
-        println!("tokens = {:?}", tokens)
+        println!("tokens = ");
+        for token in tokens.iter() {
+            println!("\t{:?}", token.contents)
+        }
     } else {
         println!("{:?}", token_errors)
     }
-    let (parsed, parse_errors) = parse(0, text.as_bytes());
-    if parse_errors.is_empty() {
-        println!("parsed = {:?}", parsed);
+    let mut parser = Parser::new(0, tokens);
+    let parsed = parser.parse_expression();
+    if parser.errors().is_empty() {
+        println!("parsed = {:#?}", parsed);
     } else {
-        println!("{:?}", parse_errors);
+        println!("{:?}", parser.errors());
     }
 }
diff --git a/src/parser.rs b/src/parser.rs
new file mode 100644
index 0000000..9fa9a64
--- /dev/null
+++ b/src/parser.rs
@@ -0,0 +1,91 @@
+use crate::{common::*, lexer::*};
+
+#[derive(Debug)]
+pub enum ParsedExpression {
+    Expression(Box<ParsedExpression>, Span),
+    Add(Box<ParsedExpression>, Box<ParsedExpression>, Span),
+    Int(String, Span),
+    Invalid(Error, Span),
+}
+
+impl ParsedExpression {
+    pub fn span(&self) -> &Span {
+        match self {
+            ParsedExpression::Expression(_, span) => span,
+            ParsedExpression::Add(_, _, span) => span,
+            ParsedExpression::Int(_, span) => span,
+            ParsedExpression::Invalid(_, span) => span,
+        }
+    }
+}
+
+pub struct Parser {
+    file_id: FileId,
+    tokens: Vec<Token>,
+    errors: Vec<Error>,
+    index: usize,
+}
+
+impl Parser {
+    pub fn new(file_id: FileId, tokens: Vec<Token>) -> Self {
+        Self {
+            file_id,
+            tokens,
+            errors: Vec::new(),
+            index: 0,
+        }
+    }
+
+    pub fn errors(&self) -> Vec<Error> {
+        self.errors.clone()
+    }
+
+    pub fn parse_expression(&mut self) -> ParsedExpression {
+        self.parse_prec_11()
+    }
+
+    pub fn parse_prec_11(&mut self) -> ParsedExpression {
+        let left = self.parse_value();
+        if self.index >= self.tokens.len() {
+            return left;
+        }
+        let operator = self.tokens[self.index].clone();
+        match operator.contents {
+            TokenContents::Plus => {
+                self.index += 1;
+                let right = self.parse_prec_11();
+                let span = Span::merge(left.span(), right.span());
+                ParsedExpression::Add(Box::new(left), Box::new(right), span)
+            }
+            _ => left,
+        }
+    }
+
+    pub fn parse_value(&mut self) -> ParsedExpression {
+        let token = self.tokens[self.index].clone();
+        self.index += 1;
+        match token.contents {
+            TokenContents::Int(value) => ParsedExpression::Int(value, token.span),
+            TokenContents::LParen => {
+                let expr = self.parse_expression();
+                match self.tokens[self.index].contents {
+                    TokenContents::RParen => {
+                        let rparen = self.tokens[self.index].clone();
+                        self.index += 1;
+                        ParsedExpression::Expression(
+                            Box::new(expr),
+                            Span::merge(&token.span, &rparen.span),
+                        )
+                    }
+                    _ => ParsedExpression::Invalid(
+                        Error::ParserError("unexpected token".into()),
+                        Span::merge(&token.span, &self.tokens[self.index].span),
+                    ),
+                }
+            }
+            _ => {
+                ParsedExpression::Invalid(Error::ParserError("unexpected token".into()), token.span)
+            }
+        }
+    }
+}
-- 
2.25.1

